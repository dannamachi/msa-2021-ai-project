{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\r\n",
        "ws = Workspace(subscription_id=\"751bc669-6f29-4b8d-8a5c-ded54299723f\",\r\n",
        "               resource_group=\"play-estimator\",\r\n",
        "               workspace_name=\"play-estimator-ws\")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1628351629873
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "# Download model\r\n",
        "\r\n",
        "# Register model\r\n",
        "model = Model.register(ws, model_name=\"MSA_regmodel_3\", model_path=\"./outputs/reg_model.pkl\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model MSA_regmodel_3\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628351631761
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "\r\n",
        "env = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "# dummy_inference_config = InferenceConfig(\r\n",
        "#     environment=env,\r\n",
        "#     source_directory=\"./source_dir\",\r\n",
        "#     entry_script=\"echo_score.py\",\r\n",
        "# )\r\n",
        "python_packages = ['joblib', 'pandas']\r\n",
        "for package in python_packages:\r\n",
        "    env.python.conda_dependencies.add_pip_package(package)\r\n",
        "\r\n",
        "inf_config = InferenceConfig(environment=env, source_directory='./source_dir', entry_script='./echo_score.py')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n"
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628357191370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import LocalWebservice\r\n",
        "\r\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6799)"
      ],
      "outputs": [],
      "execution_count": 74,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628358112623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service = Model.deploy(\r\n",
        "    ws,\r\n",
        "    \"myservice5\",\r\n",
        "    [model],\r\n",
        "    inf_config,\r\n",
        "    deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning, custom base image or base dockerfile detected without a specified `inferencing_stack_version`. Please set environment.inferencing_stack_version='latest'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model MSA_regmodel_3:1 to /tmp/azureml_o8ahzwhq/MSA_regmodel_3/1\n",
            "Generating Docker build context.\n",
            "Package creation Succeeded\n",
            "Logging into Docker registry viennaglobal.azurecr.io\n",
            "Logging into Docker registry viennaglobal.azurecr.io\n",
            "Building Docker image from Dockerfile...\n",
            "Step 1/5 : FROM viennaglobal.azurecr.io/azureml/azureml_19e3c6a5a651c2b5f1598e216869e4a8\n",
            " ---> 6c8b0854ee7f\n",
            "Step 2/5 : COPY azureml-app /var/azureml-app\n",
            " ---> 05056d50d4c8\n",
            "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijc1MWJjNjY5LTZmMjktNGI4ZC04YTVjLWRlZDU0Mjk5NzIzZiIsInJlc291cmNlR3JvdXBOYW1lIjoicGxheS1lc3RpbWF0b3IiLCJhY2NvdW50TmFtZSI6InBsYXktZXN0aW1hdG9yLXdzIiwid29ya3NwYWNlSWQiOiI2MmMyMGNkYS00MzY3LTQ0NzctOTdjNS1iZDcwZDkxOWI5ZTkifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
            " ---> Running in 02a2c6e20b02\n",
            " ---> 4279e3002b63\n",
            "Step 4/5 : RUN mv '/var/azureml-app/tmpxrit9zm3.py' /var/azureml-app/main.py\n",
            " ---> Running in b3c6ff119f0f\n",
            " ---> 1e3ebab4d60b\n",
            "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
            " ---> Running in 908a497d7197\n",
            " ---> cd2ff08ca452\n",
            "Successfully built cd2ff08ca452\n",
            "Successfully tagged myservice5:latest\n",
            "Container has been successfully cleaned up.\n",
            "Image sha256:a7d73dc823cfa86b73d9272792d706218186b407e5bcc1d4bc8197f8c3d5e597 successfully removed.\n",
            "Starting Docker container...\n",
            "Docker container running.\n",
            "Checking container health...\n",
            "Local webservice is running at http://localhost:6799\n",
            "2021-08-07T17:42:15,383296473+00:00 - iot-server/run \n",
            "2021-08-07T17:42:15,387084770+00:00 - rsyslog/run \n",
            "2021-08-07T17:42:15,389471668+00:00 - gunicorn/run \n",
            "Dynamic Python package installation is disabled.\n",
            "Starting HTTP server\n",
            "2021-08-07T17:42:15,401833058+00:00 - nginx/run \n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-08-07T17:42:15,483129094+00:00 - iot-server/finish 1 0\n",
            "2021-08-07T17:42:15,484312793+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 20.1.0\n",
            "Listening at: http://127.0.0.1:31311 (16)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 40\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-08-07 17:42:15,935 | root | INFO | Starting up app insights client\n",
            "logging socket was found. logging is available.\n",
            "logging socket was found. logging is available.\n",
            "2021-08-07 17:42:15,935 | root | INFO | Starting up request id generator\n",
            "2021-08-07 17:42:15,935 | root | INFO | Starting up app insight hooks\n",
            "2021-08-07 17:42:15,936 | root | INFO | Invoking user's init function\n",
            "/azureml-envs/sklearn-0.24.1/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LinearRegression from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "no request id,/azureml-envs/sklearn-0.24.1/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LinearRegression from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "\n",
            "2021-08-07 17:42:16,181 | root | INFO | Users's init has completed successfully\n",
            "2021-08-07 17:42:16,183 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-08-07 17:42:16,183 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-08-07 17:42:16,183 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
            "\n"
          ]
        }
      ],
      "execution_count": 75,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628358136893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "uri = service.scoring_uri\r\n",
        "\r\n",
        "data = {\r\n",
        "    'data': [\r\n",
        "        10, 10, 3, 1, 2, 10, 3\r\n",
        "    ]\r\n",
        "}\r\n",
        "\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "data = json.dumps(data)\r\n",
        "response = requests.post(uri, data=data, headers=headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': [5391.107033028812], 'message': 'Successfully predicted!'}\n"
          ]
        }
      ],
      "execution_count": 76,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628358143437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice, Webservice\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "service = Model.deploy(ws, \"aciservice\", [model], inf_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-08-07 17:51:15+00:00 Creating Container Registry if not exists.\n",
            "2021-08-07 17:51:16+00:00 Registering the environment.\n",
            "2021-08-07 17:51:18+00:00 Use the existing image.\n",
            "2021-08-07 17:51:18+00:00 Generating deployment configuration.\n",
            "2021-08-07 17:51:18+00:00 Submitting deployment to compute..\n",
            "2021-08-07 17:51:28+00:00 Checking the status of deployment aciservice..\n",
            "2021-08-07 17:54:02+00:00 Checking the status of inference endpoint aciservice.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628358843999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service = Webservice(workspace=ws, name=\"aciservice\")\r\n",
        "uri = service.scoring_uri\r\n",
        "\r\n",
        "data = {\r\n",
        "    'data': [\r\n",
        "        10, 10, 3, 1, 2, 10, 3\r\n",
        "    ]\r\n",
        "}\r\n",
        "\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "data = json.dumps(data)\r\n",
        "response = requests.post(uri, data=data, headers=headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': [5391.107033028812], 'message': 'Successfully predicted!'}\n"
          ]
        }
      ],
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628358990504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}